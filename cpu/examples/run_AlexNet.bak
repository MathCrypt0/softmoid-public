#!/usr/bin/env python
# coding=utf-8
"""
   Ant Group
   Copyright (c) 2004-2021 All Rights Reserved.
   ------------------------------------------------------
   File Name : run_Alexnet.py
   Author : Qizhi Zhang
   Email: qizhi.zqz@antgroup.com
   Create Time : 2021/9/2 上午11:08
   Description : description what the main function of this file
"""

from stensorflow.global_var import StfConfig
from stensorflow.engine.start_server import start_local_server, start_client


from tensorflow.python.keras.utils import np_utils
import numpy as np
start_local_server(config_file="../conf/config.json")

# start_client(config_file="../conf/config.json", job_name="workerR")
import time
import tensorflow as tf
from stensorflow.ml.nn.networks.AlexNet import AlexNet
from cnn_utils import convert_datasets, load_data_mnist, calculate_score_mnist, load_data_cifar10, calculate_score_cifar10

epoch = 10 # 5
batch_size = 32 # 128
learning_rate = 0.005
momentum = 0.8
l2_regularzation = None #0.01

def cnn_baseline(train_x, train_y, test_x, test_y, train=True, save_model_path="../output/complex_mnist_model.h5"):
    """
    network C using Keras
    :return:
    """
    use_bias = False
    if train:
        model = tf.keras.models.Sequential([

            # tf.keras.layers.ZeroPadding2D((9, 9), input_shape=(32, 32, 3)),
            # tf.keras.layers.Conv2D(96, (11, 11), strides=(4, 4), padding='valid', activation='relu'),
            tf.keras.layers.Conv2D(96, (11, 11), strides=(4, 4), padding='same', activation='relu', input_shape=(32, 32, 3), use_bias=use_bias),
            tf.keras.layers.AveragePooling2D((3, 3), strides=(2, 2)),

            tf.keras.layers.Conv2D(256, (5, 5), activation='relu', padding='same', use_bias=use_bias),
            tf.keras.layers.AveragePooling2D((3, 3), strides=(2, 2)),

            tf.keras.layers.Conv2D(384, (3, 3), activation='relu', padding='same', use_bias=use_bias),
            tf.keras.layers.Conv2D(384, (3, 3), activation='relu', padding='same', use_bias=use_bias),
            tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', use_bias=use_bias),


            tf.keras.layers.Flatten(),
            # Third layer
            tf.keras.layers.Dense(256, activation='relu'),
            # Final Layer
            tf.keras.layers.Dense(256, activation='relu'),
            tf.keras.layers.Dense(10, name="Dense"),
            tf.keras.layers.Activation('softmax')
        ])
        opt = tf.keras.optimizers.SGD(lr=learning_rate, momentum=momentum)
        # opt = tf.keras.optimizers.RMSprop()
        model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])

        model.summary()
        print("start train model")
        start_time = time.time()
        model.fit(train_x, train_y, epochs=epoch, batch_size=batch_size)
        end_time = time.time()
        print("train time=", end_time - start_time)
        # print(model.get_weights())
        # test result
        print("test result")
        # evaluate
        test_loss = model.evaluate(test_x, test_y)
        print("test result: " + str(test_loss))
        model.save(save_model_path)
    else:
        print("train 1 epoch using model load")
        keras_model = tf.keras.models.load_model(save_model_path)
        train_x = train_x[:batch_size]
        train_y = train_y[:batch_size]
        Epoch = 1
        for _ in range(Epoch):
            keras_model.fit(train_x, train_y, epochs=1, batch_size=batch_size)
        test_loss = keras_model.evaluate(test_x, test_y)
        print("keras test result: " + str(test_loss))
        keras_model.save("../output/complex_epoch.h5")



def stf_cnn_test(train_x, train_y, test_x, test_y, epochs, load_model=None, save_model_path="../output/complex_CNN.npz"):
    """
    NETWORK D using STF
    :param train_x: figure for training
    :param train_y: figure for label
    :param test_x: figure for training
    :param test_y: figure for label
    :param load_model:   initial weight of format of Keras
    :return:
    """
    sess = tf.compat.v1.Session(StfConfig.target)
    record_num = train_x.shape[0]
    batch_num_per_epoch = record_num // batch_size
    train_batch_num = epochs * batch_num_per_epoch
    # train_batch_num = 21
    print("train_batch_num: " + str(train_batch_num))
    pred_batch_num = test_x.shape[0] // batch_size
    # convert the data
   #print("l113, train_x=", train_x)
    x_train, y_train, x_test, y_test = convert_datasets(train_x=train_x, train_y=train_y,
                                                        test_x=test_x, test_y=test_y, size=(32, 32, 3),
                                                        epoch=epochs, batch_size=batch_size, classes_num=10)

    print("l116 xtrain=", x_train.shape)
    print("l117 y_train=", y_train.shape)
    # build model
    model = AlexNet(feature=x_train, label=y_train)
    # pred = model.predict(x_test)
    # print("pred=", pred)
    if load_model is not None:
        # load weights
        print("start replace")
        # print("load_model=", load_model)
        model.replace_weight(load_model)
    # compile model
    model.compile()
    print("success compile")
    print("start train model")
    start_time = time.time()
    model.train_sgd(learning_rate=learning_rate, batch_num=train_batch_num, l2_regularization=l2_regularzation, sess=sess, momentum=momentum)
    end_time = time.time()
    print("train time=", end_time - start_time)
    # random.random_init(sess)
    print("start predict")
    model.predict_to_file(sess, x_test, StfConfig.predict_to_file, pred_batch_num=pred_batch_num,
                          model_file_machine='R', out_prob=False)
    if save_model_path:
        model.save_model(save_file_path=save_model_path, sess=sess, model_file_machine='R')



if __name__ == "__main__":


    StfConfig.default_fixed_point = 24
    StfConfig.softmax_iter_num = 32
    train_x, train_y, test_x, test_y = load_data_cifar10(normal=False, small=False)

    print("x_train.shape=", train_x.shape)
    print("y_train.shape=", train_y.shape)

        #x_train=x_train.astype('float32')/255
        #x_test=x_test.astype('float32')/255


        #x_train_mean = np.mean(x_train)
        #x_test_mean = np.mean(x_test)

        #x_train -= x_train_mean
        #x_test -= x_test_mean


    # cnn_baseline(train_x, train_y, test_x, test_y, train=True)
    # keras_weight = None
    # keras_model = tf.keras.models.load_model("../output/complex_mnist_model.h5")
    # keras_weight = keras_model.get_weights()
    # print("keras_weight=", [np.max(np.abs(w)) for w in keras_weight])
    keras_weight = None
        # test_loss = keras_model.evaluate(test_x, test_y)
        # print("keras test result: " + str(test_loss))
        # exit()

    # for _ in range(epoch):
    #     if _ == 0 and keras_weight is not None:
    #         model_data = keras_weight
    #     else:
    #         model_data = np.load("../output/complex_CNN.npz", allow_pickle=True)
        #print("model_data=", model_data.files)
    #stf_cnn_test(train_x, train_y, test_x, test_y, epochs=1, load_model=model_data['weight'], save_model_path="../output/complex_CNN.npz")
    # learning_rate = 0.0025
    StfConfig.truncation_functionality = True
    # StfConfig.positive_truncation_without_error = True
    stf_cnn_test(train_x, train_y, test_x, test_y, epochs=epoch, load_model=keras_weight,
                 save_model_path="../output/complex_CNN.npz")

    calculate_score_cifar10(StfConfig.predict_to_file)


        # compare_forward(keras_model_path="../output/complex_mnist_model.h5",
        #                 stf_predict_path="../output/complex_mnist_predict.txt",
        #                 test_x=test_x)
         #compare_weight(keras_model_path="../output/complex_epoch.h5",
        #                stf_model_path="../output/complex_CNN.npz")

